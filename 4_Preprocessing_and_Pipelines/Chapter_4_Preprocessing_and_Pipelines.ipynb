{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 - Preprocessing and Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Learn how to impute missing values, convert categorical data to numeric values, scale data, evaluate multiple supervised learning models simultaneously, and build pipelines to streamline your workflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Preprocessing data\n",
    "\n",
    "scikit-learn requirements:\n",
    "- Numeric data\n",
    "- No missing values\n",
    "- With real-world data:\n",
    "    - This is rarely the case\n",
    "    - We will often need to preprocess our data first\n",
    "\n",
    "\n",
    "### Example of Dealing with categorical features\n",
    "\n",
    "- scikit-learn will not accept categorical features by default\n",
    "- Need to convert categorical features into numeric values\n",
    "- Convert to binary features called dummy variables:\n",
    "    - 0: Observation was NOT that category\n",
    "    - 1: Observation was that category\n",
    "\n",
    "![](./images/dummies.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reduce the **Rock** column, as if all other columns are zeros, then it should be **Rock** genre.\n",
    "\n",
    "### Dealing with categorical features in Python\n",
    "- scikit-learn:``` OneHotEncoder()```\n",
    "- pandas: ```get_dummies()```\n",
    "\n",
    "\n",
    "### Music dataset\n",
    "- popularity : Target variable\n",
    "- genre : Categorical feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36506</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.726</td>\n",
       "      <td>214547.0</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.1160</td>\n",
       "      <td>-14.824</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>92.934</td>\n",
       "      <td>0.618</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37591</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>0.635</td>\n",
       "      <td>190448.0</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.083400</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>-4.795</td>\n",
       "      <td>0.0563</td>\n",
       "      <td>110.012</td>\n",
       "      <td>0.637</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37658</th>\n",
       "      <td>59.0</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.352</td>\n",
       "      <td>456320.0</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>-3.634</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>122.897</td>\n",
       "      <td>0.228</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36060</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.488</td>\n",
       "      <td>352280.0</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>-12.020</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>106.063</td>\n",
       "      <td>0.323</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35710</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>273693.0</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.0633</td>\n",
       "      <td>-7.787</td>\n",
       "      <td>0.0487</td>\n",
       "      <td>143.995</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       popularity  acousticness  danceability  duration_ms  energy  instrumentalness  liveness  loudness  speechiness    tempo  valence  genre\n",
       "36506        60.0      0.896000         0.726     214547.0   0.177          0.000002    0.1160   -14.824       0.0353   92.934    0.618      1\n",
       "37591        63.0      0.003840         0.635     190448.0   0.908          0.083400    0.2390    -4.795       0.0563  110.012    0.637      1\n",
       "37658        59.0      0.000075         0.352     456320.0   0.956          0.020300    0.1250    -3.634       0.1490  122.897    0.228      1\n",
       "36060        54.0      0.945000         0.488     352280.0   0.326          0.015700    0.1190   -12.020       0.0328  106.063    0.323      1\n",
       "35710        55.0      0.245000         0.667     273693.0   0.647          0.000297    0.0633    -7.787       0.0487  143.995    0.300      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['popularity', 'acousticness', 'danceability', 'duration_ms', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence', 'genre']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 36506 to 18960\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   popularity        1000 non-null   float64\n",
      " 1   acousticness      1000 non-null   float64\n",
      " 2   danceability      1000 non-null   float64\n",
      " 3   duration_ms       1000 non-null   float64\n",
      " 4   energy            1000 non-null   float64\n",
      " 5   instrumentalness  1000 non-null   float64\n",
      " 6   liveness          1000 non-null   float64\n",
      " 7   loudness          1000 non-null   float64\n",
      " 8   speechiness       1000 non-null   float64\n",
      " 9   tempo             1000 non-null   float64\n",
      " 10  valence           1000 non-null   float64\n",
      " 11  genre             1000 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 101.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "music_clean_df = pd.read_csv('./datasets/music_clean.csv',index_col=[0])\n",
    "display(music_clean_df.head())\n",
    "cols = music_clean_df.columns.to_list()\n",
    "print(cols)\n",
    "print(music_clean_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   popularity        1000 non-null   float64\n",
      " 1   acousticness      1000 non-null   float64\n",
      " 2   danceability      1000 non-null   float64\n",
      " 3   duration_ms       1000 non-null   float64\n",
      " 4   energy            1000 non-null   float64\n",
      " 5   instrumentalness  1000 non-null   float64\n",
      " 6   liveness          1000 non-null   float64\n",
      " 7   loudness          1000 non-null   float64\n",
      " 8   speechiness       1000 non-null   float64\n",
      " 9   tempo             1000 non-null   float64\n",
      " 10  valence           1000 non-null   float64\n",
      " 11  genre             1000 non-null   object \n",
      "dtypes: float64(11), object(1)\n",
      "memory usage: 93.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0468</td>\n",
       "      <td>0.499</td>\n",
       "      <td>321573.0</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.703</td>\n",
       "      <td>-3.661</td>\n",
       "      <td>0.0966</td>\n",
       "      <td>110.046</td>\n",
       "      <td>0.357</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.886</td>\n",
       "      <td>135622.0</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.108</td>\n",
       "      <td>-6.177</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>92.505</td>\n",
       "      <td>0.280</td>\n",
       "      <td>Rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0414</td>\n",
       "      <td>0.399</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.264</td>\n",
       "      <td>-2.928</td>\n",
       "      <td>0.0458</td>\n",
       "      <td>184.018</td>\n",
       "      <td>0.659</td>\n",
       "      <td>Anime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.795</td>\n",
       "      <td>249271.0</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-7.926</td>\n",
       "      <td>0.0907</td>\n",
       "      <td>110.025</td>\n",
       "      <td>0.292</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0732</td>\n",
       "      <td>0.572</td>\n",
       "      <td>463240.0</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.007280</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-10.134</td>\n",
       "      <td>0.0399</td>\n",
       "      <td>134.657</td>\n",
       "      <td>0.201</td>\n",
       "      <td>Blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  acousticness  danceability  duration_ms  energy  instrumentalness  liveness  loudness  speechiness    tempo  valence    genre\n",
       "0        51.0        0.0468         0.499     321573.0   0.934          0.000003     0.703    -3.661       0.0966  110.046    0.357     Rock\n",
       "1        64.0        0.0105         0.886     135622.0   0.676          0.000241     0.108    -6.177       0.0968   92.505    0.280      Rap\n",
       "2        25.0        0.0414         0.399         -1.0   0.817          0.000000     0.264    -2.928       0.0458  184.018    0.659    Anime\n",
       "3        52.0        0.0887         0.795     249271.0   0.633          0.000023     0.101    -7.926       0.0907  110.025    0.292  Hip-Hop\n",
       "4        22.0        0.0732         0.572     463240.0   0.346          0.007280     0.148   -10.134       0.0399  134.657    0.201    Blues"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "music_df_full = pd.read_csv('./datasets/music_genre.csv',index_col=0)\n",
    "music_df_full.rename(columns={'music_genre': 'genre'}, inplace=True)\n",
    "music_df_full = music_df_full.loc[music_df_full['tempo'] != '?']\n",
    "\n",
    "music_df = music_df_full[cols].sample(1000)\n",
    "music_df['tempo'] = music_df['tempo'].astype(float)\n",
    "\n",
    "music_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(music_df.info())\n",
    "display(music_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Anime  Blues  Classical  Country  Electronic  Hip-Hop  Jazz  Rap  Rock\n",
      "0      0      0          0        0           0        0     0    0     1\n",
      "1      0      0          0        0           0        0     0    1     0\n",
      "2      1      0          0        0           0        0     0    0     0\n",
      "3      0      0          0        0           0        1     0    0     0\n",
      "4      0      1          0        0           0        0     0    0     0\n"
     ]
    }
   ],
   "source": [
    "music_dummies = pd.get_dummies(music_df['genre'], drop_first=True)\n",
    "print(music_dummies.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_dummies = pd.concat([music_df, music_dummies], axis=1)\n",
    "music_dummies = music_dummies.drop(\"genre\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['popularity', 'acousticness', 'danceability', 'duration_ms', 'energy',\n",
      "       'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo',\n",
      "       'valence', 'genre_Anime', 'genre_Blues', 'genre_Classical',\n",
      "       'genre_Country', 'genre_Electronic', 'genre_Hip-Hop', 'genre_Jazz',\n",
      "       'genre_Rap', 'genre_Rock'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Encoding dummy variables\n",
    "music_dummies = pd.get_dummies(music_df, drop_first=True)\n",
    "print(music_dummies.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.54345254 10.32756613 10.37540973 10.27973571 10.14184684]\n"
     ]
    }
   ],
   "source": [
    "# Linear regression with dummy variables\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "X = music_dummies.drop(\"popularity\", axis=1).values\n",
    "y = music_dummies[\"popularity\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "linreg = LinearRegression()\n",
    "linreg_cv = cross_val_score(linreg, X_train, y_train, cv=kf,\n",
    "scoring=\"neg_mean_squared_error\")\n",
    "print(np.sqrt(-linreg_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dummy variables (Exercise)\n",
    "\n",
    "Being able to include categorical features in the model building process can enhance performance as they may add information that contributes to prediction accuracy.\n",
    "\n",
    "The `music_df` dataset has been preloaded for you, and its shape is printed. Also, `pandas` has been imported as `pd`.\n",
    "\n",
    "Now you will create a new `DataFrame` containing the original columns of `music_df` plus dummy variables from the \"`genre`\" column.\n",
    "\n",
    "Instructions:\n",
    "- Use a relevant function, passing the entire `music_df` DataFrame, to create `music_dummies`, dropping the first binary column.\n",
    "- Print the shape of `music_dummies`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of music_dummies: (1000, 20)\n"
     ]
    }
   ],
   "source": [
    "# Create music_dummies\n",
    "music_dummies = pd.get_dummies(music_df, drop_first=True)\n",
    "\n",
    "# Print the new DataFrame's shape\n",
    "print(\"Shape of music_dummies: {}\".format(music_dummies.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there were ten values in the \"genre\" column, nine new columns were added by a call of `pd.get_dummies()` using `drop_first=True`. \n",
    "\n",
    "After dropping the original \"`genre`\" column, there are still eight new columns in the DataFrame!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression with categorical features (Exercise)\n",
    "\n",
    "Now you have created music_dummies, containing binary features for each song's genre, it's time to build a ridge regression model to predict song popularity.\n",
    "\n",
    "`music_dummies` has been preloaded for you, along with `Ridge`, `cross_val_score`, `numpy as np`, and a `KFold` object stored as `kf`.\n",
    "\n",
    "The model will be evaluated by calculating the average **RMSE**, but first, you will need to convert the scores for each fold to positive values and take their square root. \n",
    "This metric shows the average error of our model's predictions, so it can be compared against the standard deviation of the target value—\"popularity\".\n",
    "\n",
    "Instructions:\n",
    "- Create `X`, containing all features in `music_dummies`, and `y`, consisting of the \"`popularity`\" column, respectively.\n",
    "- Instantiate a ridge regression model, setting `alpha` equal to `0.2`.\n",
    "- Perform cross-validation on `X` and `y` using the `ridge` model, setting `cv` equal to `kf`, and using negative mean squared error as the scoring metric.\n",
    "- Print the `RMSE` values by converting negative scores to positive and taking the square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE: 10.03832835646816\n",
      "Standard Deviation of the target array: 15.578642302845266\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "# Create X and y\n",
    "X = music_dummies.drop(['popularity'], axis =1).values\n",
    "y = music_dummies['popularity'].values\n",
    "\n",
    "# Instantiate a ridge model\n",
    "ridge = Ridge( alpha=0.2)\n",
    "\n",
    "# Perform cross-validation\n",
    "scores = cross_val_score(ridge, X, y, cv=kf, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(-scores)\n",
    "print(\"Average RMSE: {}\".format(np.mean(rmse)))\n",
    "print(\"Standard Deviation of the target array: {}\".format(np.std(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! An average RMSE of approximately **9.4** is lower than the standard deviation of the target variable (song popularity), suggesting the model is reasonably accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Handling missing data\n",
    "\n",
    "- Missing data\n",
    "- No value for a feature in a particular row\n",
    "- This can occur because:\n",
    "    - There may have been no observation\n",
    "    - The data might be corrupt\n",
    "- We need to deal with missing data\n",
    "\n",
    "![](./images/missing_1.png)\n",
    "\n",
    "![](./images/missing_2.png)\n",
    "\n",
    "![](./images/missing_3.png)\n",
    "\n",
    "![](./images/missing_4.png)\n",
    "\n",
    "![](./images/missing_5.png)\n",
    "\n",
    "![](./images/missing_6.png)\n",
    "\n",
    "![](./images/missing_7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dropping missing data\n",
    "\n",
    "Over the next three exercises, you are going to tidy the `music_df` dataset. You will create a pipeline to impute missing values and build a **KNN classifier model**, then use it to predict whether a song is of the \"**Rock**\" genre.\n",
    "\n",
    "In this exercise specifically, you will drop missing values accounting for less than 5% of the dataset, and convert the \"genre\" column into a binary feature.\n",
    "\n",
    "Instructions:\n",
    "- Print the number of missing values for each column in the `music_df` dataset, sorted in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popularity          0\n",
      "acousticness        0\n",
      "danceability        0\n",
      "duration_ms         0\n",
      "energy              0\n",
      "instrumentalness    0\n",
      "liveness            0\n",
      "loudness            0\n",
      "speechiness         0\n",
      "tempo               0\n",
      "valence             0\n",
      "genre               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print missing values for each column\n",
    "print(music_df.isna().sum().sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove values for all columns with 50 or fewer missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popularity          0\n",
      "acousticness        0\n",
      "danceability        0\n",
      "duration_ms         0\n",
      "energy              0\n",
      "instrumentalness    0\n",
      "liveness            0\n",
      "loudness            0\n",
      "speechiness         0\n",
      "tempo               0\n",
      "valence             0\n",
      "genre               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print missing values for each column\n",
    "print(music_df.isna().sum().sort_values())\n",
    "lessthan50NanCols = [i for i in music_df.columns if music_df[i].isna().sum() <= 50]\n",
    "\n",
    "# Remove values where less than 5% are missing\n",
    "music_df = music_df.dropna(subset = lessthan50NanCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert `music_df[\"genre\"]` to values of 1 if the row contains \"Rock\", otherwise change the value to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popularity          0\n",
      "acousticness        0\n",
      "danceability        0\n",
      "duration_ms         0\n",
      "energy              0\n",
      "instrumentalness    0\n",
      "liveness            0\n",
      "loudness            0\n",
      "speechiness         0\n",
      "tempo               0\n",
      "valence             0\n",
      "genre               0\n",
      "dtype: int64\n",
      "popularity          0\n",
      "acousticness        0\n",
      "danceability        0\n",
      "duration_ms         0\n",
      "energy              0\n",
      "instrumentalness    0\n",
      "liveness            0\n",
      "loudness            0\n",
      "speechiness         0\n",
      "tempo               0\n",
      "valence             0\n",
      "genre               0\n",
      "dtype: int64\n",
      "Shape of the `music_df`: (1000, 12)\n"
     ]
    }
   ],
   "source": [
    "# Print missing values for each column\n",
    "print(music_df.isna().sum().sort_values())\n",
    "\n",
    "# Remove values where less than 5% are missing\n",
    "music_df = music_df.dropna(subset=[\"genre\", \"popularity\", \"loudness\", \"liveness\", \"tempo\"])\n",
    "\n",
    "# Convert genre to a binary feature\n",
    "music_df[\"genre\"] = np.where(music_df[\"genre\"] == \"Rock\", 1, 0)\n",
    "\n",
    "print(music_df.isna().sum().sort_values())\n",
    "print(\"Shape of the `music_df`: {}\".format(music_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline for song genre prediction: I\n",
    "\n",
    "Now it's time to build a **pipeline**. It will contain steps to impute missing values using the mean for each feature and build a KNN model for the classification of song genre.\n",
    "\n",
    "The modified `music_df` dataset that you created in the previous exercise has been preloaded for you, along with `KNeighborsClassifier` and `train_test_split`.\n",
    "\n",
    "Instructions:\n",
    "- Import `SimpleImputer` and `Pipeline`.\n",
    "- Instantiate an `imputer`.\n",
    "- Instantiate a KNN classifier with three neighbors.\n",
    "- Create steps, a list of tuples containing the imputer variable you created, called \"`imputer`\", followed by the `knn` model you created,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Instantiate an imputer\n",
    "imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "# Instantiate a knn model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Build steps for the pipeline\n",
    "steps = [(\"imputer\", imputer), \n",
    "         (\"knn\", knn)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Pipeline for song genre prediction: II\n",
    "Having set up the steps of the pipeline in the previous exercise, you will now use it on the `music_df` dataset to classify the genre of songs. \n",
    "What makes pipelines so incredibly useful is the simple interface that they provide.\n",
    "\n",
    "`X_train`, `X_test`, `y_train`, and `y_test` have been preloaded for you, and `confusion_matrix` has been imported from `sklearn.metrics`.\n",
    "\n",
    "Instructions:\n",
    "- Create a pipeline using the steps you previously defined.\n",
    "- Fit the pipeline to the training data.\n",
    "- Make predictions on the test set.\n",
    "- Calculate and print the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean = SimpleImputer(strategy=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "steps = [(\"imputer\", imp_mean),\n",
    "        (\"knn\", knn)]\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centering and scaling\n",
    "\n",
    "![](./images/scale1.png)\n",
    "\n",
    "\n",
    "### Why scale our data?\n",
    "\n",
    "- Many models use some form of distance to inform them\n",
    "- Features on larger scales can disproportionately influence the model\n",
    "- Example: KNN uses distance explicitly when making predictions\n",
    "- We want features to be on a similar scale\n",
    "- Normalizing or standardizing (scaling and centering)\n",
    "\n",
    "### How to scale our data\n",
    "\n",
    "- Subtract the mean and divide by variance\n",
    "    - All features are centered around zero and have a variance of one\n",
    "    - This is called **standardization**\n",
    "- Can also subtract the minimum and divide by the range\n",
    "    - Minimum zero and maximum one\n",
    "- Can also normarmalize so the data ranges from -1 to +1\n",
    "- See scikit-learn docs for further details\n",
    "\n",
    "\n",
    "\n",
    "### Scaling in scikit-learn\n",
    "\n",
    "```python \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = music_df.drop(\"genre\", axis=1).values\n",
    "y = music_df[\"genre\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(np.mean(X), np.std(X))\n",
    "print(np.mean(X_train_scaled), np.std(X_train_scaled))\n",
    "\n",
    "```\n",
    "\n",
    "### Scaling in a pipeline\n",
    "\n",
    "``` python \n",
    "\n",
    "steps = [('scaler', StandardScaler()),('knn', KNeighborsClassifier(n_neighbors=6))]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)\n",
    "\n",
    "knn_scaled = pipeline.fit(X_train, y_train)\n",
    "y_pred = knn_scaled.predict(X_test)\n",
    "print(knn_scaled.score(X_test, y_test))\n",
    "```\n",
    "\n",
    "### Comparing performance using unscaled data\n",
    "\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)\n",
    "knn_unscaled = KNeighborsClassifier(n_neighbors=6).fit(X_train, y_train)\n",
    "print(knn_unscaled.score(X_test, y_test))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV and scaling in a pipeline\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "steps = [('scaler', StandardScaler()),('knn', KNeighborsClassifier())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "parameters = {\"knn__n_neighbors\": np.arange(1, 50)}\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=21)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "cv.fit(X_train, y_train)\n",
    "y_pred = cv.predict(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centering and scaling for regression (Exercise)\n",
    "\n",
    "Now you have seen the benefits of scaling your data, you will use a pipeline to pre-process the `music_df` features and build a lasso regression model to predict a song's loudness.\n",
    "\n",
    "`X_train`, `X_test`, `y_train`, and `y_test` have been created from the `music_df` dataset, where the target is \"`loudness`\" and the features are all other columns in the dataset. Lasso and Pipeline have also been imported for you.\n",
    "\n",
    "Note that \"`genre`\" has been converted to a binary feature where 1 indicates a rock song, and 0 represents other genres.\n",
    "\n",
    "Instructions:\n",
    "- Import `StandardScaler`.\n",
    "- Create the steps for the pipeline object, a `StandardScaler` object called \"`scaler`\", and a lasso model called \"`lasso`\" with alpha set to 0.5.\n",
    "- Instantiate a pipeline with steps to scale and build a lasso regression model.\n",
    "- Calculate the R-squared value on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.006181318681318659\n"
     ]
    }
   ],
   "source": [
    "# Import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "X = music_df.drop(\"genre\", axis=1).values\n",
    "y = music_df[\"genre\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create pipeline steps\n",
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"lasso\", Lasso(alpha=0.5))]\n",
    "\n",
    "# Instantiate the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Calculate and print R-squared\n",
    "print(pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Centering and scaling for  classification (Exercise)\n",
    "\n",
    "Now you will bring together scaling and model building into a pipeline for cross-validation.\n",
    "\n",
    "Your task is to build a pipeline to scale features in the `music_df` dataset and perform grid search cross-validation using a logistic regression model with different values for the hyperparameter C. The target variable here is \"genre\", which contains binary values for rock as 1 and any other genre as 0.\n",
    "\n",
    "`StandardScaler`, `LogisticRegression`, and `GridSearchCV` have all been imported for you.\n",
    "\n",
    "Instructions:\n",
    "- Build the steps for the pipeline: a `StandardScaler()` object named \"`scaler`\", and a logistic regression model named \"`logreg`\".\n",
    "- Create the parameters, searching 20 equally spaced float values ranging from `0.001` to `1.0` for the logistic regression model's C hyperparameter within the pipeline.\n",
    "- Instantiate the grid search object.\n",
    "- Fit the grid search object to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90625 \n",
      " {'logreg__C': 0.36905263157894735}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Build the steps for the pipeline: a `StandardScaler()` object named \"`scaler`\", and a logistic regression model named \"`logreg`\".\n",
    "\n",
    "steps = [   \n",
    "               (\"scaler\", StandardScaler()),\n",
    "               (\"logreg\", LogisticRegression())\n",
    "            ]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Create the `parameters`, searching 20 equally spaced float values ranging from 0.001 to 1.0 for the logistic regression model's C hyperparameter within the pipeline\n",
    "\n",
    "parameters = {\"logreg__C\": np.linspace(0.001, 1.0, 20)}\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=21)\n",
    "\n",
    "# Instantiate the grid search object\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "# Fit to the training data\n",
    "cv.fit(X_train, y_train)\n",
    "print(cv.best_score_, \"\\n\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating multiple models\n",
    "\n",
    "Different models for different problems\n",
    "\n",
    "### Some guiding principles\n",
    "\n",
    "- Size of the dataset\n",
    "    - Fewer features = simpler model, faster training time\n",
    "    - Some models require large amounts of data to perform well\n",
    "\n",
    "- Interpretability\n",
    "    - Some models are easier to explain, which can be important for stakeholders\n",
    "    - Linear regression has high interpretability, as we can understand the coefficients\n",
    "\n",
    "- Flexibility\n",
    "    - May improve accuracy, by making fewer assumptions about data\n",
    "    - KNN is a more flexible model, doesn't assume any linear relationships\n",
    "\n",
    "\n",
    "### It's all in the metrics\n",
    "\n",
    "- Regression model performance:\n",
    "    - RMSE\n",
    "    - R-squared\n",
    "\n",
    "- Classification model performance:\n",
    "    - Accuracy\n",
    "    - Confusion matrix\n",
    "    - Precision, recall, F1-score\n",
    "    - ROC AUC\n",
    "\n",
    "- Train several models and evaluate performance out of the box\n",
    "\n",
    "### A note on scaling\n",
    "\n",
    "- Models a(ected by scaling:\n",
    "    - KNN\n",
    "    - Linear Regression (plus Ridge, Lasso)\n",
    "    - Logistic Regression\n",
    "    - Artificial Neural Network\n",
    "- Best to scale our data before evaluating models\n",
    "\n",
    "\n",
    "### Evaluating classification models\n",
    "\n",
    "``` python\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X = music.drop(\"genre\", axis=1).values\n",
    "y = music[\"genre\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "```\n",
    "\n",
    "### Evaluating classification models\n",
    "\n",
    "``` python\n",
    "\n",
    "models = {  \n",
    "            \"Logistic Regression\": LogisticRegression(),\n",
    "            \"KNN\": KNeighborsClassifier(),\n",
    "            \"Decision Tree\": DecisionTreeClassifier()\n",
    "        }\n",
    "\n",
    "results = []\n",
    "for model in models.values():\n",
    "    kf = KFold(n_splits=6, random_state=42, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train_scaled, y_train, cv=kf)\n",
    "    results.append(cv_results)\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "![](./images/viz.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Visualizing regression model performance (Exercise)\n",
    "\n",
    "Now you have seen how to evaluate multiple models out of the box, you will build three regression models to predict a song's \"`energy`\" levels.\n",
    "\n",
    "The `music_df` dataset has had dummy variables for \"`genre`\" added. Also, feature and target arrays have been created, and these have been split into `X_train`, `X_test`, `y_train`, and `y_test`.\n",
    "\n",
    "The following have been imported for you: `LinearRegression`, `Ridge`, `Lasso`, `cross_val_score`, and `KFold`.\n",
    "\n",
    "Instructions:\n",
    "- Write a for loop using `model` as the iterator, and `model.values()` as the iterable.\n",
    "- Perform cross-validation on the training features and the training target array using the model, setting `cv` equal to the `KFold` object.\n",
    "- Append the model's cross-validation scores to the results list.\n",
    "- Create a box plot displaying the results, with the x-axis labels as the names of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models = {\n",
    "            \"Linear Regression\": LinearRegression(), \n",
    "            \"Ridge\": Ridge(alpha=0.1), \n",
    "            \"Lasso\": Lasso(alpha=0.1)\n",
    "            }\n",
    "results = []\n",
    "\n",
    "# Loop through the models' values\n",
    "for model in models.values():\n",
    "  kf = KFold(n_splits=6, random_state=42, shuffle=True)\n",
    "  \n",
    "  # Perform cross-validation\n",
    "  cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "  \n",
    "  # Append the results\n",
    "  results.append(cv_scores)\n",
    "\n",
    "# Create a box plot of the results\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on the test set (Exercise)\n",
    "\n",
    "In the last exercise, linear regression and ridge appeared to produce similar results. It would be appropriate to select either of those models; however, you can check predictive performance on the test set to see if either one can outperform the other.\n",
    "\n",
    "You will use root mean squared error (RMSE) as the metric. The dictionary models, containing the names and instances of the two models, has been preloaded for you along with the training and target arrays `X_train_scaled`, `X_test_scaled`, `y_train`, and `y_test`.\n",
    "\n",
    "Instructions:\n",
    "- Import `mean_squared_error`.\n",
    "- Fit the model to the scaled training features and the training labels.\n",
    "- Make predictions using the scaled test features.\n",
    "- Calculate RMSE by passing the test set labels and the predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Set RMSE: 0.322490309931942\n",
      "KNN Test Set RMSE: 0.3286335345030997\n",
      "Decision Tree Test Set RMSE: 0.37416573867739417\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X = music_df.drop(\"genre\", axis=1).values\n",
    "y = music_df[\"genre\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "models = {  \n",
    "            \"Logistic Regression\": LogisticRegression(),\n",
    "            \"KNN\": KNeighborsClassifier(),\n",
    "            \"Decision Tree\": DecisionTreeClassifier()\n",
    "        }\n",
    "\n",
    "for name, model in models.items():\n",
    "  \n",
    "  # Fit the model to the training data\n",
    "  model.fit(X_train_scaled, y_train)\n",
    "  \n",
    "  # Make predictions on the test set\n",
    "  y_pred = model.predict(X_test_scaled)\n",
    "  \n",
    "  # Calculate the test_rmse\n",
    "  test_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "  print(\"{} Test Set RMSE: {}\".format(name, test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing classification model performance (Exercise)\n",
    "\n",
    "In this exercise, you will be solving a classification problem where the \"`popularity`\" column in the music_df dataset has been converted to binary values, with 1 representing popularity more than or equal to the median for the \"`popularity`\" column, and 0 indicating popularity below the median.\n",
    "\n",
    "Your task is to build and visualize the results of three different models to classify whether a song is popular or not.\n",
    "\n",
    "The data has been split, scaled, and preloaded for you as `X_train_scaled`, `X_test_scaled`, `y_train`, and `y_test`. Additionally, `KNeighborsClassifier`, `DecisionTreeClassifier`, and `LogisticRegression` have been imported.\n",
    "\n",
    "Instructions:\n",
    "- Create a dictionary of \"Logistic Regression\", \"KNN\", and \"Decision Tree Classifier\", setting the dictionary's values to a call of each model.\n",
    "- Loop through the values in models.\n",
    "- Instantiate a `KFold` object to perform 6 splits, setting `shuffle` to `True` and `random_state` to 12.\n",
    "- Perform cross-validation using the model, the scaled training features, the target training set, and setting `cv` equal to `kf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create models dictionary\n",
    "models = {\"Logistic Regression\": LogisticRegression(), \n",
    "          \"KNN\": KNeighborsClassifier(),\n",
    "          \"Decision Tree Classifier\": DecisionTreeClassifier()}\n",
    "results = []\n",
    "\n",
    "# Loop through the models' values\n",
    "for model in models.values():\n",
    "  \n",
    "  # Instantiate a KFold object\n",
    "  kf = KFold(n_splits=6, random_state=12, shuffle=True)\n",
    "  \n",
    "  # Perform cross-validation\n",
    "  cv_results = cross_val_score(model, X_train_scaled, y_train, cv=kf)\n",
    "  results.append(cv_results)\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Pipeline for predicting song popularity (Exercise)\n",
    "For the final exercise, you will build a pipeline to impute missing values, scale features, and perform hyperparameter tuning of a logistic regression model. \n",
    "The aim is to find the best parameters and accuracy when predicting song genre!\n",
    "\n",
    "All the models and objects required to build the pipeline have been preloaded for you.\n",
    "\n",
    "Instructions:\n",
    "- Create the steps for the pipeline by calling a simple imputer, a standard scaler, and a logistic regression model.\n",
    "- Create a pipeline object, and pass the steps variable.\n",
    "- Instantiate a grid search object to perform cross-validation using the pipeline and the parameters.\n",
    "- Print the best parameters and compute and print the test set accuracy score for the grid search object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'logreg__C': 0.112, 'logreg__solver': 'newton-cg'}, Accuracy: 0.912\n"
     ]
    }
   ],
   "source": [
    "# Create steps\n",
    "steps = [(\"imp_mean\", SimpleImputer()), \n",
    "         (\"scaler\", StandardScaler()), \n",
    "         (\"logreg\", LogisticRegression())]\n",
    "\n",
    "# Set up pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "params = {\"logreg__solver\": [\"newton-cg\", \"saga\", \"lbfgs\"],\n",
    "         \"logreg__C\": np.linspace(0.001, 1.0, 10)}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "tuning = GridSearchCV(pipeline, param_grid=params)\n",
    "tuning.fit(X_train, y_train)\n",
    "y_pred = tuning.predict(X_test)\n",
    "\n",
    "# Compute and print performance\n",
    "print(\"Tuned Logistic Regression Parameters: {}, Accuracy: {}\".format(tuning.best_params_, tuning.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What you've covered\n",
    "\n",
    "- Using supervised learning techniques to build predictive models\n",
    "- For both regression and classi,cation problems\n",
    "- Underfitting and overfittng\n",
    "- How to split data\n",
    "- Cross-validation\n",
    "- Data preprocessing techniques\n",
    "- Model selection\n",
    "- Hyperparameter tuning\n",
    "- Model performance evaluation\n",
    "- Using pipelines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
